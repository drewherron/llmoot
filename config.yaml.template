# llmoot Configuration File
# Copy this to config.yaml and customize as needed

# API Keys - Set these or use environment variables
# Environment variables are checked first.
api_keys:
  anthropic: ${ANTHROPIC_API_KEY}
  openai: ${OPENAI_API_KEY}
  google: ${GOOGLE_API_KEY}

# Model & Provider Settings
# -------------------------
# This section allows you to define models, their properties (like context limits),
# and which model to use for different quality levels. This makes it easy to
# add new models or change defaults without editing the application code.

# 1. Model Catalog
# Define all known models and their specific properties here.
# The most important property is `context_limit`.
model_catalog:
  # OpenAI Models
  'gpt-4o': { context_limit: 128000 }
  'gpt-4-turbo': { context_limit: 128000 }
  'gpt-4-32k': { context_limit: 32768 }
  'gpt-4': { context_limit: 8192 }
  'gpt-3.5-turbo-16k': { context_limit: 16384 }
  'gpt-3.5-turbo': { context_limit: 4096 }

  # Google Models
  'gemini-2.5-pro': { context_limit: 1000000 }
  'gemini-1.5-pro': { context_limit: 1000000 }
  'gemini-pro': { context_limit: 32768 }

  # Anthropic Models
  'claude-3-opus-20240229': { context_limit: 200000 }
  'claude-3-sonnet-20240229': { context_limit: 200000 }
  'claude-3-haiku-20240307': { context_limit: 200000 }

# 2. Model Selection by Quality
# Map providers to a specific model from the catalog for each quality level.
# Quality levels are arbitrary integers. You can define as many as you like.
# The --quality-level CLI flag will use the integer you specify here.
models:
  1:  # Corresponds to --quality-level 1
    claude: 'claude-3-opus-20240229'
    openai: 'gpt-4o'
    gemini: 'gemini-2.5-pro'

  2:  # Corresponds to --quality-level 2
    claude: 'claude-3-sonnet-20240229'
    openai: 'gpt-3.5-turbo-16k'
    gemini: 'gemini-1.5-pro'
  
  3: # Example of a third, even faster/cheaper level
    claude: 'claude-3-haiku-20240307'
    openai: 'gpt-3.5-turbo'
    gemini: 'gemini-pro'

# System Prompts - Customize how LLMs are instructed
system_prompts:
  intermediate: |
    You are participating in a collaborative roundtable discussion with other AI assistants.
    Your role is to provide thoughtful insights that complement previous responses, add new perspectives,
    and build upon good points made by others. Focus on content and ideas, not final formatting.
  final: |
    You are the final participant in a collaborative roundtable discussion.
    Your role is to synthesize the best insights from all previous responses into a comprehensive
    final answer. Apply any formatting requested by the user.

# Default Settings
defaults:
  quality_level: 1

# Logging Settings
logging:
  enabled: true
  directory: "logs"
